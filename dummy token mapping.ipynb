{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d449450c-25f7-4c1a-840c-6d6a129d185c",
   "metadata": {},
   "source": [
    "The goal of this notebook is to understand how the mapping between dummy tokens from the source prompt to the target prompt should look like.\n",
    "\n",
    "Example with max_len=5 (and ignoring start/end tokens):\n",
    "```\n",
    "p_src = [feroci, us, turtle]\n",
    "p_tgt = [sad, turtle]\n",
    "```\n",
    "\n",
    "Weifeng implements the mapper as\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 \\\\\n",
    "1 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "whereas I think the `1` in the second column is wrong, and the matrix should therefore be\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 \\\\\n",
    "1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "\\text{or}\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 \\\\\n",
    "1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "but I'm not sure about the mapping of the diagonal after the 1st row, which represent the dummy tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aaa1c3-5021-4735-a3ce-6c7d3e27b90f",
   "metadata": {},
   "source": [
    "### Setup & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7dd9b02-7a92-49a3-9e12-4612d4bb8a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq fastcore accelerate transformers diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55aa671-adea-4a1b-8d88-76350e02b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, tensor\n",
    "from torchvision.transforms import ToTensor\n",
    "from fastcore.all import *\n",
    "np.set_printoptions(precision=2, linewidth=140)\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2365d88-a9d7-433c-83ba-7ad8e57d287e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n"
     ]
    }
   ],
   "source": [
    "from P2P import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b4d811-97d0-437d-bccb-aa343cb3d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "g_cpu = torch.Generator().manual_seed(2333)\n",
    "prompts = ['ferocious turtle',\n",
    "           'sad turtle']\n",
    "NUM_DIFFUSION_STEPS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a73786-a734-46bb-a633-9204af35d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = LoggedVars()  # logger for attention controller\n",
    "la = LoggedVars()  # logger for attention application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdef13c2-5c68-43ff-af3f-721e7c39ca0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6eb1fb6046c4c4185e7e4fbe19ec5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "pipe = Prompt2PromptPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", attn_logger=la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69a49f4-6f37-4948-90d2-3986e7a96448",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = AttentionReplace(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=0.4, self_replace_steps=0.4, tokenizer=pipe.tokenizer, device=pipe.device, logger=lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafa0f2c-3a2b-4f0f-8890-f81d24ef9b33",
   "metadata": {},
   "source": [
    "Now, let's run it once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a766c4ff-370e-4058-b2a8-d632e947f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diffusers/notebooks/P2P.py:304: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
      "  num_channels_latents = self.unet.in_channels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afb69c65dc14e7ea4d4ba0c130e6743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:422: FutureWarning: The decode_latents method is deprecated and will be removed in a future version. Please use VaeImageProcessor instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(prompt=prompts, height=512, width=512, num_inference_steps=NUM_DIFFUSION_STEPS, controller=controller, generator=g_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "715664b9-cee6-4a34-8b22-f218da26c052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['attn', 'hidden_states__passed', 'encoder_hidden_states__passed', 'attention_mask__passed', 'batch_size', 'sequence_length', 'attn#prepare_attention_mask', 'attention_mask', 'query__pre_h2b', 'is_cross', 'encoder_hidden_states', 'key__pre_h2b', 'value__pre_h2b', 'query', 'key', 'value', 'attention_probs__precontrol', 'attn#get_attention_scores', 'attention_probs__postcontrol', 'place_in_unet', 'hidden_states_1', 'hidden_states_2', 'hidden_states_3', 'hidden_states_4', 'attn#to_out', 'attn#head_to_batch_dim', 'attn#batch_to_head_dim'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "828ee418-b274-4768-85a7-e14df51592d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mapper', 'self', 'attn', 'is_cross', 'place_in_unet'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a922aa-5e2d-4ff7-8765-41a3a3321b14",
   "metadata": {},
   "source": [
    "### Okay, let's get to it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c74f4b-dbbf-4084-ab2f-a60c6708e922",
   "metadata": {},
   "source": [
    "**Important Note:** I discorverd that Weifeng copied the replacement part of the code from the paper authors's [repo](https://github.com/google/prompt-to-prompt/blob/main/seq_aligner.py#L189).\n",
    "<br/>\n",
    "So, for the implementation in Diffusers, I should assume the code is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d8119-928b-48aa-8a91-051c60e1c343",
   "metadata": {},
   "source": [
    "Still, I believe the the mapping to be wrong. I will check that out after implementing P2P into diffusers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf22b3bb-461e-4a77-b2e6-75ae0fe62cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
